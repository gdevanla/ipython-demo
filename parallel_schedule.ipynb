{
 "metadata": {
  "name": "",
  "signature": "sha256:1903228108160ea2dc687e248bb3130fea710d98bf4331acfafdd6e46a6ad4e4"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# In this example, we will extend the data structures we had previously used to enable parallel running of tasks\n",
      "\n",
      "# Some assumptions and hard-coded values\n",
      "\n",
      "# a. Assume each schedule job can spawn its own set of threads without any other constraints.\n",
      "# b. Queue get() blocking times are arbitrary.\n",
      "# c. We assume the number of simulations in a workflow are few compared to the amount of time it takes to complete an simulation. \n",
      "#    Hence, we can survive on spawning a small number of threads for each scheduled job"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# We will have a class ScheduleJob which has the following properties\n",
      "\n",
      "# 1.  A python Queue, `q` - we use it since it is synchronized\n",
      "# 2.  Two dict, one to store the original order of dependencies and second to store the reverse order. \n",
      "# As, jobs complete we lookup `rev_dep` and update `orig_dep`. Once `orig_dep` is empty we signal to the threads that \n",
      "# all jobs have been enqueued.\n",
      "# 3.  The `workflow` object is not update in this case, since we keep track of changes with orig_dep dict. \n",
      "# Also, we isolate multiple thread updates to `orig_dep` data.\n",
      "\n",
      "#TODOs :  Error Handling, start() getting called multiple times, hard-coded thread count, timeout values, better exception \n",
      "# handling for blocking get()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import time\n",
      "from threading import Lock, Thread\n",
      "from Queue import Queue\n",
      "from collections import defaultdict\n",
      "\n",
      "\n",
      "class ScheduledJob():\n",
      "\n",
      "    def __init__(self, workflow):\n",
      "        self.wf = workflow\n",
      "        self.orig_dep = self._build_dependency_graph(workflow)\n",
      "        self.rev_dep = self._build_rev_dependency_graph(workflow)\n",
      "        self.q = Queue()\n",
      "        self.all_tasks_queued = False\n",
      "        self.lock = Lock()\n",
      "\n",
      "    def _build_dependency_graph(self, workflow):\n",
      "        d = defaultdict(set)\n",
      "        for k, v in workflow.iteritems():\n",
      "            d[k] = d[k] | set(v['depends'])\n",
      "\n",
      "        return d\n",
      "\n",
      "    def _build_rev_dependency_graph(self, workflow):\n",
      "        d = defaultdict(set)\n",
      "        for k, v in self.wf.iteritems():\n",
      "            if v['depends']:\n",
      "                for c in v['depends']:\n",
      "                    d[c] = d[c] | {k}\n",
      "\n",
      "        return d\n",
      "\n",
      "    def start(self):\n",
      "        for jobid, v in self.wf.iteritems():\n",
      "            if not v['depends']:\n",
      "                del self.orig_dep[jobid]\n",
      "                self.q.put(jobid) # enqueue all the nodes that do not have parents\n",
      "\n",
      "        self.run_parallel_process()\n",
      "\n",
      "    def update_job_status(self, jobid):\n",
      "        # does not handle cases when parent job fails\n",
      "        with self.lock:\n",
      "            children = self.rev_dep[jobid]\n",
      "            for c in children:\n",
      "                self.orig_dep[c] = self.orig_dep[c] - {jobid}\n",
      "                if not self.orig_dep[c]: #all parents executed\n",
      "                    del self.orig_dep[c]\n",
      "                    self.q.put(c)\n",
      "\n",
      "            if not self.orig_dep:\n",
      "                self.all_tasks_queued = True\n",
      "\n",
      "    def run_parallel_process(self):\n",
      "        # hard-coded to 2 threads\n",
      "        for i in range(2):\n",
      "            t = Thread(target=self.worker)\n",
      "            t.daemon = True\n",
      "            t.start()\n",
      "            time.sleep(1) #slow down for print statements\n",
      "\n",
      "    def worker(self):\n",
      "        while not self.all_tasks_queued:\n",
      "            try:\n",
      "                item = self.q.get(True, 1)\n",
      "                self.wf[item]['action'](self.wf[item]['param'])\n",
      "                self.update_job_status(item)\n",
      "            except:\n",
      "                time.sleep(5)\n",
      "                pass #try again\n",
      "\n",
      "        while self.q.empty():\n",
      "            try:\n",
      "                item = self.q.get(True, 1)\n",
      "                self.wf[item]['action'](self.wf[item]['param'])\n",
      "            except:\n",
      "                pass\n",
      "\n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def sim_func(id):\n",
      "    print 'Running job with id =', id"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "user_workflow =  { 1 : { 'action' : sim_func, 'param': 11, 'depends' : {}},\n",
      "                       2 : { 'action' : sim_func, 'param': 12, 'depends' : {}},\n",
      "                       3 : { 'action' : sim_func, 'param': 13, 'depends' : {1,2}},\n",
      "                       4:  { 'action' : sim_func, 'param': 14,  'depends' : {3,2}}}\n",
      "\n",
      "sj = ScheduledJob(user_workflow)\n",
      "sj.start()\n",
      "\n",
      "user_workflow2 = {  1 : { 'action' : sim_func, 'param': 21, 'depends' : {}},\n",
      "                       2 : { 'action' : sim_func, 'param': 22, 'depends' : {}},\n",
      "                        4 : { 'action' : sim_func, 'param': 24, 'depends' : {3}},\n",
      "                        3:  { 'action' : sim_func, 'param': 23,  'depends' : {1,2}}}\n",
      "\n",
      "sj = ScheduledJob(user_workflow2)\n",
      "sj.start()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Running job with id = 11\n",
        "Running job with id = 12\n",
        "Running job with id = 13\n",
        "Running job with id = 21\n",
        "Running job with id = 22\n",
        "Running job with id = 23\n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    }
   ],
   "metadata": {}
  }
 ]
}